// Paebiru Distributed ML - Federated Averaging
// Implements FedAvg and variants for distributed model training
//
// FedAvg: McMahan et al., "Communication-Efficient Learning of Deep Networks
// from Decentralized Data", AISTATS 2017

// Helper: Create ByteSil from magnitude
fn from_mag(m: Float) -> ByteSil {
    return bytesil_new(floor(clamp_float(ln(max_float(m, 0.0001)), -8.0, 7.0)), 0);
}

// Helper: Add two states
fn add_st(a: State, b: State) -> State {
    let r = state_vacuum();
    let r = state_set_layer(r, 0, complex_add(state_get_layer(a, 0), state_get_layer(b, 0)));
    let r = state_set_layer(r, 1, complex_add(state_get_layer(a, 1), state_get_layer(b, 1)));
    let r = state_set_layer(r, 2, complex_add(state_get_layer(a, 2), state_get_layer(b, 2)));
    let r = state_set_layer(r, 3, complex_add(state_get_layer(a, 3), state_get_layer(b, 3)));
    let r = state_set_layer(r, 4, complex_add(state_get_layer(a, 4), state_get_layer(b, 4)));
    let r = state_set_layer(r, 5, complex_add(state_get_layer(a, 5), state_get_layer(b, 5)));
    let r = state_set_layer(r, 6, complex_add(state_get_layer(a, 6), state_get_layer(b, 6)));
    let r = state_set_layer(r, 7, complex_add(state_get_layer(a, 7), state_get_layer(b, 7)));
    let r = state_set_layer(r, 8, complex_add(state_get_layer(a, 8), state_get_layer(b, 8)));
    let r = state_set_layer(r, 9, complex_add(state_get_layer(a, 9), state_get_layer(b, 9)));
    let r = state_set_layer(r, 10, complex_add(state_get_layer(a, 10), state_get_layer(b, 10)));
    let r = state_set_layer(r, 11, complex_add(state_get_layer(a, 11), state_get_layer(b, 11)));
    let r = state_set_layer(r, 12, complex_add(state_get_layer(a, 12), state_get_layer(b, 12)));
    let r = state_set_layer(r, 13, complex_add(state_get_layer(a, 13), state_get_layer(b, 13)));
    let r = state_set_layer(r, 14, complex_add(state_get_layer(a, 14), state_get_layer(b, 14)));
    let r = state_set_layer(r, 15, complex_add(state_get_layer(a, 15), state_get_layer(b, 15)));
    return r;
}

// Helper: Subtract two states
fn sub_st(a: State, b: State) -> State {
    let r = state_vacuum();
    let r = state_set_layer(r, 0, complex_sub(state_get_layer(a, 0), state_get_layer(b, 0)));
    let r = state_set_layer(r, 1, complex_sub(state_get_layer(a, 1), state_get_layer(b, 1)));
    let r = state_set_layer(r, 2, complex_sub(state_get_layer(a, 2), state_get_layer(b, 2)));
    let r = state_set_layer(r, 3, complex_sub(state_get_layer(a, 3), state_get_layer(b, 3)));
    let r = state_set_layer(r, 4, complex_sub(state_get_layer(a, 4), state_get_layer(b, 4)));
    let r = state_set_layer(r, 5, complex_sub(state_get_layer(a, 5), state_get_layer(b, 5)));
    let r = state_set_layer(r, 6, complex_sub(state_get_layer(a, 6), state_get_layer(b, 6)));
    let r = state_set_layer(r, 7, complex_sub(state_get_layer(a, 7), state_get_layer(b, 7)));
    let r = state_set_layer(r, 8, complex_sub(state_get_layer(a, 8), state_get_layer(b, 8)));
    let r = state_set_layer(r, 9, complex_sub(state_get_layer(a, 9), state_get_layer(b, 9)));
    let r = state_set_layer(r, 10, complex_sub(state_get_layer(a, 10), state_get_layer(b, 10)));
    let r = state_set_layer(r, 11, complex_sub(state_get_layer(a, 11), state_get_layer(b, 11)));
    let r = state_set_layer(r, 12, complex_sub(state_get_layer(a, 12), state_get_layer(b, 12)));
    let r = state_set_layer(r, 13, complex_sub(state_get_layer(a, 13), state_get_layer(b, 13)));
    let r = state_set_layer(r, 14, complex_sub(state_get_layer(a, 14), state_get_layer(b, 14)));
    let r = state_set_layer(r, 15, complex_sub(state_get_layer(a, 15), state_get_layer(b, 15)));
    return r;
}

// Helper: Scale state by scalar
fn scale_st(s: State, scalar: Float) -> State {
    let r = state_vacuum();
    let r = state_set_layer(r, 0, complex_scale(state_get_layer(s, 0), scalar));
    let r = state_set_layer(r, 1, complex_scale(state_get_layer(s, 1), scalar));
    let r = state_set_layer(r, 2, complex_scale(state_get_layer(s, 2), scalar));
    let r = state_set_layer(r, 3, complex_scale(state_get_layer(s, 3), scalar));
    let r = state_set_layer(r, 4, complex_scale(state_get_layer(s, 4), scalar));
    let r = state_set_layer(r, 5, complex_scale(state_get_layer(s, 5), scalar));
    let r = state_set_layer(r, 6, complex_scale(state_get_layer(s, 6), scalar));
    let r = state_set_layer(r, 7, complex_scale(state_get_layer(s, 7), scalar));
    let r = state_set_layer(r, 8, complex_scale(state_get_layer(s, 8), scalar));
    let r = state_set_layer(r, 9, complex_scale(state_get_layer(s, 9), scalar));
    let r = state_set_layer(r, 10, complex_scale(state_get_layer(s, 10), scalar));
    let r = state_set_layer(r, 11, complex_scale(state_get_layer(s, 11), scalar));
    let r = state_set_layer(r, 12, complex_scale(state_get_layer(s, 12), scalar));
    let r = state_set_layer(r, 13, complex_scale(state_get_layer(s, 13), scalar));
    let r = state_set_layer(r, 14, complex_scale(state_get_layer(s, 14), scalar));
    let r = state_set_layer(r, 15, complex_scale(state_get_layer(s, 15), scalar));
    return r;
}

// ============ FedAvg Core ============

// Simple average of 2 models (equal weights)
fn fedavg_2(m1: State, m2: State) -> State {
    let sum = add_st(m1, m2);
    return scale_st(sum, 0.5);
}

// Simple average of 3 models
fn fedavg_3(m1: State, m2: State, m3: State) -> State {
    let sum = add_st(add_st(m1, m2), m3);
    return scale_st(sum, 0.333333);
}

// Simple average of 4 models
fn fedavg_4(m1: State, m2: State, m3: State, m4: State) -> State {
    let sum = add_st(add_st(m1, m2), add_st(m3, m4));
    return scale_st(sum, 0.25);
}

// Weighted average of 2 models
// w1 + w2 should equal 1.0 for proper averaging
fn fedavg_weighted_2(m1: State, w1: Float, m2: State, w2: Float) -> State {
    let scaled1 = scale_st(m1, w1);
    let scaled2 = scale_st(m2, w2);
    return add_st(scaled1, scaled2);
}

// Weighted average of 3 models
fn fedavg_weighted_3(
    m1: State, w1: Float,
    m2: State, w2: Float,
    m3: State, w3: Float
) -> State {
    let scaled1 = scale_st(m1, w1);
    let scaled2 = scale_st(m2, w2);
    let scaled3 = scale_st(m3, w3);
    return add_st(add_st(scaled1, scaled2), scaled3);
}

// Weighted average of 4 models
fn fedavg_weighted_4(
    m1: State, w1: Float,
    m2: State, w2: Float,
    m3: State, w3: Float,
    m4: State, w4: Float
) -> State {
    let scaled1 = scale_st(m1, w1);
    let scaled2 = scale_st(m2, w2);
    let scaled3 = scale_st(m3, w3);
    let scaled4 = scale_st(m4, w4);
    return add_st(add_st(scaled1, scaled2), add_st(scaled3, scaled4));
}

// ============ FedProx ============
// FedProx adds a proximal term to keep local updates close to global model
// Li et al., "Federated Optimization in Heterogeneous Networks", MLSys 2020

// Compute proximal term: mu/2 * ||w - w_global||^2
fn proximal_term(local: State, global: State, mu: Float) -> Float {
    let diff = sub_st(local, global);
    let sum_sq = 0.0;

    let d0 = bytesil_magnitude(state_get_layer(diff, 0));
    let sum_sq = sum_sq + d0 * d0;
    let d1 = bytesil_magnitude(state_get_layer(diff, 1));
    let sum_sq = sum_sq + d1 * d1;
    let d2 = bytesil_magnitude(state_get_layer(diff, 2));
    let sum_sq = sum_sq + d2 * d2;
    let d3 = bytesil_magnitude(state_get_layer(diff, 3));
    let sum_sq = sum_sq + d3 * d3;
    let d4 = bytesil_magnitude(state_get_layer(diff, 4));
    let sum_sq = sum_sq + d4 * d4;
    let d5 = bytesil_magnitude(state_get_layer(diff, 5));
    let sum_sq = sum_sq + d5 * d5;
    let d6 = bytesil_magnitude(state_get_layer(diff, 6));
    let sum_sq = sum_sq + d6 * d6;
    let d7 = bytesil_magnitude(state_get_layer(diff, 7));
    let sum_sq = sum_sq + d7 * d7;
    let d8 = bytesil_magnitude(state_get_layer(diff, 8));
    let sum_sq = sum_sq + d8 * d8;
    let d9 = bytesil_magnitude(state_get_layer(diff, 9));
    let sum_sq = sum_sq + d9 * d9;
    let d10 = bytesil_magnitude(state_get_layer(diff, 10));
    let sum_sq = sum_sq + d10 * d10;
    let d11 = bytesil_magnitude(state_get_layer(diff, 11));
    let sum_sq = sum_sq + d11 * d11;
    let d12 = bytesil_magnitude(state_get_layer(diff, 12));
    let sum_sq = sum_sq + d12 * d12;
    let d13 = bytesil_magnitude(state_get_layer(diff, 13));
    let sum_sq = sum_sq + d13 * d13;
    let d14 = bytesil_magnitude(state_get_layer(diff, 14));
    let sum_sq = sum_sq + d14 * d14;
    let d15 = bytesil_magnitude(state_get_layer(diff, 15));
    let sum_sq = sum_sq + d15 * d15;

    return mu * 0.5 * sum_sq;
}

// FedProx gradient correction: gradient + mu * (w - w_global)
fn fedprox_gradient(gradient: State, local: State, global: State, mu: Float) -> State {
    let diff = sub_st(local, global);
    let prox_grad = scale_st(diff, mu);
    return add_st(gradient, prox_grad);
}

// ============ Scaffold ============
// SCAFFOLD: Stochastic Controlled Averaging for Federated Learning
// Karimireddy et al., ICML 2020

// Update control variate after local training
// c_new = c_old - c_global + (1/K*lr) * (w_global - w_local)
fn scaffold_control_update(
    c_local: State,
    c_global: State,
    w_global: State,
    w_local: State,
    k_steps: Float,
    lr: Float
) -> State {
    let model_diff = sub_st(w_global, w_local);
    let scaled_diff = scale_st(model_diff, 1.0 / (k_steps * lr));

    let c_diff = sub_st(c_local, c_global);
    return add_st(scaled_diff, c_diff);
}

// SCAFFOLD gradient correction
fn scaffold_gradient(gradient: State, c_local: State, c_global: State) -> State {
    let c_diff = sub_st(c_global, c_local);
    return add_st(gradient, c_diff);
}

// ============ Model Delta Compression ============

// Compute model delta (update) for transmission
fn compute_delta(updated_model: State, original_model: State) -> State {
    return sub_st(updated_model, original_model);
}

// Apply delta to reconstruct model
fn apply_delta(original_model: State, delta: State) -> State {
    return add_st(original_model, delta);
}

// ============ Weight Computation ============

// Compute weights based on dataset sizes
// Returns normalized weight for client with n samples out of total N
fn compute_weight_by_samples(n_samples: Float, total_samples: Float) -> Float {
    return n_samples / max_float(total_samples, 1.0);
}

// Compute weights with fairness constraint
// Caps maximum contribution from any single client
fn compute_weight_fair(n_samples: Float, total_samples: Float, max_weight: Float) -> Float {
    let raw_weight = n_samples / max_float(total_samples, 1.0);
    return min_float(raw_weight, max_weight);
}

// Compute weights based on model quality (lower loss = higher weight)
fn compute_weight_by_loss(client_loss: Float, total_loss: Float) -> Float {
    // Inverse loss weighting
    let inv_loss = 1.0 / max_float(client_loss, 0.001);
    let total_inv = 1.0 / max_float(total_loss, 0.001);
    return inv_loss / max_float(total_inv * 4.0, 0.001);  // Assume 4 clients avg
}

// ============ Staleness Handling ============

// Apply staleness penalty to model update
// Older updates get less weight
fn staleness_weight(rounds_old: Int, decay: Float) -> Float {
    let staleness = rounds_old * 1.0;
    return exp(0.0 - decay * staleness);
}

// FedAsync: weight update by staleness
fn fedasync_weighted(
    delta: State,
    rounds_old: Int,
    mixing_param: Float
) -> State {
    let staleness_factor = staleness_weight(rounds_old, 0.5);
    let effective_weight = mixing_param * staleness_factor;
    return scale_st(delta, effective_weight);
}

// ============ Convergence Monitoring ============

// Compute L2 distance between models
fn model_distance(m1: State, m2: State) -> Float {
    let diff = sub_st(m1, m2);
    let sum_sq = 0.0;

    let d0 = bytesil_magnitude(state_get_layer(diff, 0));
    let sum_sq = sum_sq + d0 * d0;
    let d1 = bytesil_magnitude(state_get_layer(diff, 1));
    let sum_sq = sum_sq + d1 * d1;
    let d2 = bytesil_magnitude(state_get_layer(diff, 2));
    let sum_sq = sum_sq + d2 * d2;
    let d3 = bytesil_magnitude(state_get_layer(diff, 3));
    let sum_sq = sum_sq + d3 * d3;
    let d4 = bytesil_magnitude(state_get_layer(diff, 4));
    let sum_sq = sum_sq + d4 * d4;
    let d5 = bytesil_magnitude(state_get_layer(diff, 5));
    let sum_sq = sum_sq + d5 * d5;
    let d6 = bytesil_magnitude(state_get_layer(diff, 6));
    let sum_sq = sum_sq + d6 * d6;
    let d7 = bytesil_magnitude(state_get_layer(diff, 7));
    let sum_sq = sum_sq + d7 * d7;
    let d8 = bytesil_magnitude(state_get_layer(diff, 8));
    let sum_sq = sum_sq + d8 * d8;
    let d9 = bytesil_magnitude(state_get_layer(diff, 9));
    let sum_sq = sum_sq + d9 * d9;
    let d10 = bytesil_magnitude(state_get_layer(diff, 10));
    let sum_sq = sum_sq + d10 * d10;
    let d11 = bytesil_magnitude(state_get_layer(diff, 11));
    let sum_sq = sum_sq + d11 * d11;
    let d12 = bytesil_magnitude(state_get_layer(diff, 12));
    let sum_sq = sum_sq + d12 * d12;
    let d13 = bytesil_magnitude(state_get_layer(diff, 13));
    let sum_sq = sum_sq + d13 * d13;
    let d14 = bytesil_magnitude(state_get_layer(diff, 14));
    let sum_sq = sum_sq + d14 * d14;
    let d15 = bytesil_magnitude(state_get_layer(diff, 15));
    let sum_sq = sum_sq + d15 * d15;

    return sqrt(sum_sq);
}

// Check if model has converged (small change between rounds)
fn has_converged(old_model: State, new_model: State, threshold: Float) -> Bool {
    let dist = model_distance(old_model, new_model);
    return dist < threshold;
}

// Compute gradient norm (for monitoring)
fn gradient_norm(gradient: State) -> Float {
    let sum_sq = 0.0;

    let g0 = bytesil_magnitude(state_get_layer(gradient, 0));
    let sum_sq = sum_sq + g0 * g0;
    let g1 = bytesil_magnitude(state_get_layer(gradient, 1));
    let sum_sq = sum_sq + g1 * g1;
    let g2 = bytesil_magnitude(state_get_layer(gradient, 2));
    let sum_sq = sum_sq + g2 * g2;
    let g3 = bytesil_magnitude(state_get_layer(gradient, 3));
    let sum_sq = sum_sq + g3 * g3;
    let g4 = bytesil_magnitude(state_get_layer(gradient, 4));
    let sum_sq = sum_sq + g4 * g4;
    let g5 = bytesil_magnitude(state_get_layer(gradient, 5));
    let sum_sq = sum_sq + g5 * g5;
    let g6 = bytesil_magnitude(state_get_layer(gradient, 6));
    let sum_sq = sum_sq + g6 * g6;
    let g7 = bytesil_magnitude(state_get_layer(gradient, 7));
    let sum_sq = sum_sq + g7 * g7;
    let g8 = bytesil_magnitude(state_get_layer(gradient, 8));
    let sum_sq = sum_sq + g8 * g8;
    let g9 = bytesil_magnitude(state_get_layer(gradient, 9));
    let sum_sq = sum_sq + g9 * g9;
    let g10 = bytesil_magnitude(state_get_layer(gradient, 10));
    let sum_sq = sum_sq + g10 * g10;
    let g11 = bytesil_magnitude(state_get_layer(gradient, 11));
    let sum_sq = sum_sq + g11 * g11;
    let g12 = bytesil_magnitude(state_get_layer(gradient, 12));
    let sum_sq = sum_sq + g12 * g12;
    let g13 = bytesil_magnitude(state_get_layer(gradient, 13));
    let sum_sq = sum_sq + g13 * g13;
    let g14 = bytesil_magnitude(state_get_layer(gradient, 14));
    let sum_sq = sum_sq + g14 * g14;
    let g15 = bytesil_magnitude(state_get_layer(gradient, 15));
    let sum_sq = sum_sq + g15 * g15;

    return sqrt(sum_sq);
}

