// Paebiru Distributed ML - Federated Averaging
// Implementa FedAvg e variantes para treinamento distribuido
//
// FedAvg: McMahan et al., "Communication-Efficient Learning of Deep Networks
// from Decentralized Data", AISTATS 2017

use core::bytesil::{bs_mag};
use core::state::{st_add, st_sub, st_scale, st_sum_mag_sq};

// =============================================================================
// FedAvg Core
// =============================================================================

// Media simples de 2 modelos
pub fn fedavg_2(m1: State, m2: State) -> State {
    let sum = st_add(m1, m2);
    return st_scale(sum, 0.5);
}

// Media simples de 3 modelos
pub fn fedavg_3(m1: State, m2: State, m3: State) -> State {
    let sum = st_add(st_add(m1, m2), m3);
    return st_scale(sum, 0.333333);
}

// Media simples de 4 modelos
pub fn fedavg_4(m1: State, m2: State, m3: State, m4: State) -> State {
    let sum = st_add(st_add(m1, m2), st_add(m3, m4));
    return st_scale(sum, 0.25);
}

// Media ponderada de 2 modelos
pub fn fedavg_weighted_2(m1: State, w1: Float, m2: State, w2: Float) -> State {
    let scaled1 = st_scale(m1, w1);
    let scaled2 = st_scale(m2, w2);
    return st_add(scaled1, scaled2);
}

// Media ponderada de 3 modelos
pub fn fedavg_weighted_3(
    m1: State, w1: Float,
    m2: State, w2: Float,
    m3: State, w3: Float
) -> State {
    let scaled1 = st_scale(m1, w1);
    let scaled2 = st_scale(m2, w2);
    let scaled3 = st_scale(m3, w3);
    return st_add(st_add(scaled1, scaled2), scaled3);
}

// Media ponderada de 4 modelos
pub fn fedavg_weighted_4(
    m1: State, w1: Float,
    m2: State, w2: Float,
    m3: State, w3: Float,
    m4: State, w4: Float
) -> State {
    let scaled1 = st_scale(m1, w1);
    let scaled2 = st_scale(m2, w2);
    let scaled3 = st_scale(m3, w3);
    let scaled4 = st_scale(m4, w4);
    return st_add(st_add(scaled1, scaled2), st_add(scaled3, scaled4));
}

// =============================================================================
// FedProx
// =============================================================================

// Compute proximal term: mu/2 * ||w - w_global||^2
pub fn proximal_term(local: State, global: State, mu: Float) -> Float {
    let diff = st_sub(local, global);
    let sq_sum = st_sum_mag_sq(diff);
    return mu * 0.5 * sq_sum;
}

// FedProx gradient correction: gradient + mu * (w - w_global)
pub fn fedprox_gradient(gradient: State, local: State, global: State, mu: Float) -> State {
    let diff = st_sub(local, global);
    let prox_grad = st_scale(diff, mu);
    return st_add(gradient, prox_grad);
}

// =============================================================================
// Scaffold
// =============================================================================

// Update control variate after local training
pub fn scaffold_control_update(
    c_local: State,
    c_global: State,
    w_global: State,
    w_local: State,
    k_steps: Float,
    lr: Float
) -> State {
    let model_diff = st_sub(w_global, w_local);
    let scaled_diff = st_scale(model_diff, 1.0 / (k_steps * lr));
    let c_diff = st_sub(c_local, c_global);
    return st_add(scaled_diff, c_diff);
}

// SCAFFOLD gradient correction
pub fn scaffold_gradient(gradient: State, c_local: State, c_global: State) -> State {
    let c_diff = st_sub(c_global, c_local);
    return st_add(gradient, c_diff);
}

// =============================================================================
// Model Delta
// =============================================================================

// Compute model delta (update) for transmission
pub fn compute_delta(updated_model: State, original_model: State) -> State {
    return st_sub(updated_model, original_model);
}

// Apply delta to reconstruct model
pub fn apply_delta(original_model: State, delta: State) -> State {
    return st_add(original_model, delta);
}

// =============================================================================
// Weight Computation
// =============================================================================

// Compute weights based on dataset sizes
pub fn compute_weight_by_samples(n_samples: Float, total_samples: Float) -> Float {
    return n_samples / max_float(total_samples, 1.0);
}

// Compute weights with fairness constraint
pub fn compute_weight_fair(n_samples: Float, total_samples: Float, max_weight: Float) -> Float {
    let raw_weight = n_samples / max_float(total_samples, 1.0);
    return min_float(raw_weight, max_weight);
}

// Compute weights based on model quality
pub fn compute_weight_by_loss(client_loss: Float, total_loss: Float) -> Float {
    let inv_loss = 1.0 / max_float(client_loss, 0.001);
    let total_inv = 1.0 / max_float(total_loss, 0.001);
    return inv_loss / max_float(total_inv * 4.0, 0.001);
}

// =============================================================================
// Staleness Handling
// =============================================================================

// Apply staleness penalty to model update
pub fn staleness_weight(rounds_old: Int, decay: Float) -> Float {
    let staleness = rounds_old * 1.0;
    return exp(0.0 - decay * staleness);
}

// FedAsync: weight update by staleness
pub fn fedasync_weighted(delta: State, rounds_old: Int, mixing_param: Float) -> State {
    let staleness_factor = staleness_weight(rounds_old, 0.5);
    let effective_weight = mixing_param * staleness_factor;
    return st_scale(delta, effective_weight);
}

// =============================================================================
// Convergence Monitoring
// =============================================================================

// Compute L2 distance between models
pub fn model_distance(m1: State, m2: State) -> Float {
    let diff = st_sub(m1, m2);
    let sq_sum = st_sum_mag_sq(diff);
    return sqrt(sq_sum);
}

// Check if model has converged
pub fn has_converged(old_model: State, new_model: State, threshold: Float) -> Bool {
    let dist = model_distance(old_model, new_model);
    return dist < threshold;
}

// Compute gradient norm (for monitoring)
pub fn gradient_norm(gradient: State) -> Float {
    let sq_sum = st_sum_mag_sq(gradient);
    return sqrt(sq_sum);
}

