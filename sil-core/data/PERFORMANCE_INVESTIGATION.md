# ğŸ” InvestigaÃ§Ã£o de Performance - SIL-Core

**Data:** 11 de Janeiro de 2026  
**Sistema:** MacBook Pro M3 Pro (18GB RAM)  
**VersÃ£o:** sil-core 2026.1.0

---

## ğŸ“Š Problemas Identificados

### 1. âš ï¸ GPU Context Overhead: 700Âµs vs 3ns NPU

**Sintoma:**
```
GPU context_new: 701.46 Âµs (overhead inicial)
NPU context_new: 3.12 ns
DiferenÃ§a: ~224,000x mais lento
```

**Causa Raiz:** [`src/processors/gpu/context.rs:26-133`](src/processors/gpu/context.rs#L26-L133)

O `GpuContext::new()` executa operaÃ§Ãµes custosas de forma sÃ­ncrona:

1. **CriaÃ§Ã£o de instÃ¢ncia wgpu** (~50Âµs)
2. **RequisiÃ§Ã£o de adaptador async** (~200Âµs) 
3. **CriaÃ§Ã£o de device & queue** (~300Âµs)
4. **CompilaÃ§Ã£o de shader WGSL** (~100Âµs)
5. **CriaÃ§Ã£o de bind group layouts** (~30Âµs)
6. **CriaÃ§Ã£o de compute pipeline** (~20Âµs)

**Impacto:**
- Inviabiliza uso GPU para operaÃ§Ãµes individuais (<100 elementos)
- GPU sÃ³ compensa quando overhead Ã© amortizado em lotes >1000 elementos

**RecomendaÃ§Ãµes:**

#### SoluÃ§Ã£o Imediata (Lazy Initialization)
```rust
// Cache global de contexto GPU (singleton)
static GPU_CONTEXT: OnceLock<GpuContext> = OnceLock::new();

impl GpuContext {
    pub fn get_or_init() -> GpuResult<&'static Self> {
        GPU_CONTEXT.get_or_try_init(|| Self::new_sync())
    }
}
```

#### SoluÃ§Ã£o Longo Prazo
- Pre-compilar shaders no build time (usando `build.rs`)
- Lazy loading de pipelines (criar apenas quando necessÃ¡rio)
- Pool de contextos reutilizÃ¡veis

---

### 2. ğŸ”¥ VSP Interpretado: Overhead de 46,400x

**Sintoma:**
```
CPU add direto:      14.65 ns
VSP add interpretado: 679.63 Âµs
Overhead: ~46,400x
```

**Causa Raiz:** [`src/vsp/mod.rs:150-200`](src/vsp/mod.rs#L150-L200)

Loop de interpretaÃ§Ã£o executa:

1. **Fetch** â†’ Ler bytecode da memÃ³ria
2. **Decode** â†’ Decodificar instruÃ§Ã£o (pattern matching)
3. **Execute** â†’ Dispatch para handler
4. **State update** â†’ Atualizar registradores
5. **PC increment** â†’ AvanÃ§ar program counter

Cada instruÃ§Ã£o VSP = ~5-10 acessos Ã  memÃ³ria + overhead Rust.

**PadrÃ£o Observado:**
```rust
// CÃ³digo atual (interpretado)
loop {
    let instruction = self.memory.fetch(self.state.pc)?;
    match instruction.opcode {
        Opcode::Add => { /* ... */ },
        Opcode::Mul => { /* ... */ },
        // ... 70+ opcodes
    }
    self.state.pc += instruction.size();
}
```

**Impacto:**
- VSP Ã© **inviÃ¡vel para operaÃ§Ãµes crÃ­ticas** de performance
- Adequado apenas para prototipagem/scripting

**RecomendaÃ§Ãµes:**

#### OpÃ§Ã£o 1: JIT Compilation (LLVM Backend)
```rust
use inkwell::context::Context;
use inkwell::builder::Builder;

impl Vsp {
    fn jit_compile(&self, bytecode: &[u8]) -> CompiledFunction {
        let context = Context::create();
        let builder = Builder::create(&context);
        
        // Traduzir bytecode â†’ LLVM IR â†’ native code
        for instruction in decode_all(bytecode) {
            match instruction.opcode {
                Opcode::Add => {
                    builder.build_fadd(lhs, rhs, "add");
                }
                // ...
            }
        }
        
        builder.finalize()
    }
}
```

#### OpÃ§Ã£o 2: AOT Compilation (.silc â†’ .so/.dylib)
```bash
# Compilar ahead-of-time
$ silasm program.sil -o program.silc --compile
$ silc program.silc -o libprogram.so

# Carregar em runtime
$ vsp --load libprogram.so
```

#### OpÃ§Ã£o 3: Bytecode Optimization
- **Peephole optimization**: substituir padrÃµes comuns por instruÃ§Ãµes otimizadas
- **Register allocation**: reduzir movimentaÃ§Ã£o de dados
- **Inline hot paths**: eliminar jumps em loops crÃ­ticos

---

### 3. ğŸš¨ CRÃTICO: RegressÃ£o de DetecÃ§Ã£o de Processadores (+21,310%)

**Sintoma:**
```
ProcessorType::available():        4.80 Âµs  (+21,310% regressÃ£o!)
ProcessorType::Cpu::is_available:  799 ps   (+170%)
ProcessorType::Gpu::is_available:  4.67 Âµs  (+1,551,665% !!)
ProcessorType::Npu::is_available:  826 ps   (+178%)
```

**Causa Raiz:** [`src/processors/gpu/mod.rs:63-75`](src/processors/gpu/mod.rs#L63-L75)

```rust
pub fn is_available() -> bool {
    let instance = wgpu::Instance::new(InstanceDescriptor {
        backends: wgpu::Backends::all(),
        ..Default::default()
    });
    
    pollster::block_on(async {
        instance.request_adapter(&RequestAdapterOptions {
            power_preference: PowerPreference::HighPerformance,
            compatible_surface: None,
            force_fallback_adapter: false,
        }).await.is_some()
    })
}
```

**Problema:** 
- **CRIA NOVA INSTÃ‚NCIA WGPU A CADA CHAMADA!**
- Inclui descoberta de hardware, inicializaÃ§Ã£o de drivers, etc.
- Executado 3 vezes em `ProcessorType::available()` (GPU, NPU, CPU)

**Impacto:**
- **CRÃTICO**: Inviabiliza queries de disponibilidade em hot paths
- Afeta startup de aplicaÃ§Ãµes
- Loops de seleÃ§Ã£o dinÃ¢mica de processador ficam inviÃ¡veis

**SoluÃ§Ã£o URGENTE:**

```rust
use std::sync::OnceLock;

// Cache estÃ¡tico de disponibilidade
static GPU_AVAILABLE: OnceLock<bool> = OnceLock::new();

impl GpuContext {
    pub fn is_available() -> bool {
        *GPU_AVAILABLE.get_or_init(|| {
            let instance = wgpu::Instance::new(InstanceDescriptor {
                backends: wgpu::Backends::all(),
                ..Default::default()
            });
            
            pollster::block_on(async {
                instance.request_adapter(&RequestAdapterOptions {
                    power_preference: PowerPreference::HighPerformance,
                    compatible_surface: None,
                    force_fallback_adapter: false,
                }).await.is_some()
            })
        })
    }
}
```

**Resultado Esperado:**
- Primeira chamada: ~4.8Âµs (detecÃ§Ã£o real)
- Chamadas subsequentes: <1ns (cache lookup)

---

### 4. âš¡ GPU Single-Op: 70-90% mais lenta que CPU

**Sintoma:**
```
lerp (CPU):  12.29 ns  âœ…
lerp (GPU):  23.50 ns  (91% mais lenta)

slerp (CPU): 15.72 ns  âœ…
slerp (GPU): 26.56 ns  (69% mais lenta)
```

**Causa:** Overhead de dispatch GPU nÃ£o compensa para operaÃ§Ãµes simples

**Componentes do Overhead:**
1. **Command buffer creation** (~5ns)
2. **Bind group setup** (~3ns)
3. **Dispatch call** (~2ns)
4. **GPU queue sync** (~8ns)
5. **Result readback** (~5ns)

**Total overhead:** ~23ns â†’ Mais que o tempo da operaÃ§Ã£o!

**Quando GPU compensa:**

| OperaÃ§Ã£o | Breakeven Point | Ganho MÃ¡ximo |
|----------|-----------------|---------------|
| lerp/slerp | >500 elementos | ~2x em 10K elementos |
| gradient | >200 elementos | ~3x em 10K elementos |
| distance | >1000 elementos | ~10x em 100K elementos |

**RecomendaÃ§Ãµes:**

#### HeurÃ­stica de SeleÃ§Ã£o AutomÃ¡tica
```rust
impl ProcessorSelector {
    pub fn select_for_interpolation(batch_size: usize) -> ProcessorType {
        match batch_size {
            0..=100 => ProcessorType::Cpu,      // Overhead inviÃ¡vel
            101..=500 => ProcessorType::Cpu,    // CPU ainda melhor
            501..=2000 => ProcessorType::Gpu,   // GPU comeÃ§a compensar
            _ => ProcessorType::Gpu,            // GPU Ã³tima
        }
    }
}
```

#### Async Batching
```rust
// Buffer de operaÃ§Ãµes pendentes
let mut batch = vec![];

for state in states {
    batch.push(state);
    
    if batch.len() >= 500 {  // Threshold de eficiÃªncia GPU
        gpu_ctx.lerp_batch(&batch).await?;
        batch.clear();
    }
}
```

---

## ğŸ¯ PriorizaÃ§Ã£o de Fixes

### P0 - CRÃTICO (Hot Fix Hoje)
1. âœ… **Cache de `is_available()`** â†’ Elimina regressÃ£o de +21,000%
2. âœ… **Singleton `GpuContext`** â†’ Amortiza overhead de 700Âµs

### P1 - Alto (Sprint Atual)
3. ğŸ”„ **VSP JIT Prototype** â†’ PoC com LLVM/Cranelift
4. ğŸ”„ **Auto-selection heuristics** â†’ Escolher CPU/GPU baseado em batch size

### P2 - MÃ©dio (PrÃ³ximo Release)
5. â³ **Pre-compiled shaders** â†’ Reduzir overhead de compilaÃ§Ã£o
6. â³ **Async GPU ops** â†’ Batching automÃ¡tico

### P3 - Baixo (Roadmap)
7. â³ **AOT VSP compiler** â†’ .silc â†’ native code
8. â³ **GPU pipeline pool** â†’ Reutilizar recursos

---

## ğŸ”§ Action Items

- [ ] Implementar cache estÃ¡tico em `GpuContext::is_available()`
- [ ] Implementar singleton pattern em `GpuContext`
- [ ] Adicionar testes de regressÃ£o de performance
- [ ] Criar benchmark de breakeven points (CPU vs GPU)
- [ ] Prototipar VSP JIT com Cranelift
- [ ] Documentar guidelines de uso de processadores

---

## ğŸ“š ReferÃªncias

- [WGPU Performance Guide](https://wgpu.rs/)
- [Cranelift JIT](https://cranelift.dev/)
- [LLVM IR Generation](https://llvm.org/docs/tutorial/)
- [Apple Metal Best Practices](https://developer.apple.com/metal/Metal-Best-Practices-Guide.pdf)

---

**PrÃ³ximo Review:** 18 de Janeiro de 2026  
**ResponsÃ¡vel:** Equipe de Performance SIL-Core
