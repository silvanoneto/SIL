# ğŸ” Performance Regression Testing

Sistema automatizado para detectar regressÃµes de performance no cÃ³digo GPU.

## ğŸ¯ Objetivo

Garantir que mudanÃ§as futuras nÃ£o degradem a performance alcanÃ§ada pelo sistema de batching GPU assÃ­ncrono.

## ğŸ“Š MÃ©tricas Monitoradas

### 1. **Throughput MÃ­nimo**
- **Baseline**: 50K estados/segundo (mÃ­nimo aceitÃ¡vel)
- **Target**: 200K estados/segundo (M3 Pro)
- **Test**: `benchmark_minimum_throughput`

### 2. **LatÃªncia MÃ¡xima**
- **Baseline**: 5ms para 16 estados
- **Target**: <2ms para 16 estados
- **Test**: `benchmark_maximum_latency`

### 3. **Vantagem de Batching**
- **Baseline**: Batched deve ser >5x mais rÃ¡pido que sequential
- **Target**: >10x mais rÃ¡pido
- **Test**: `benchmark_batching_vs_sequential`

### 4. **Paridade InterpolaÃ§Ã£o/Gradientes**
- **Baseline**: InterpolaÃ§Ã£o deve ter Â±20% da performance de gradientes
- **Target**: Performance similar
- **Test**: `benchmark_interpolate_parity`

### 5. **Overhead de Batching**
- **Baseline**: Diferentes batch sizes devem escalar linearmente
- **Target**: Overhead <10%
- **Test**: `benchmark_batching_overhead`

### 6. **Escalabilidade Paralela**
- **Baseline**: 2x tasks = ~1.8x throughput (90% eficiÃªncia)
- **Target**: >80% eficiÃªncia atÃ© 8 tasks
- **Test**: `benchmark_parallel_scalability`

## ğŸš€ Uso

### Rodar Testes de RegressÃ£o

```bash
# Rodar benchmarks
cargo bench --features gpu --bench gpu_regression

# Rodar script de validaÃ§Ã£o
./scripts/check_performance_regression.sh

# Rodar com baseline comparison
cargo bench --features gpu --bench gpu_regression -- --baseline baseline
```

### Criar Baseline

```bash
# Primeira vez: criar baseline de referÃªncia
cargo bench --features gpu --bench gpu_regression -- --save-baseline baseline

# Comparar com baseline
cargo bench --features gpu --bench gpu_regression -- --baseline baseline
```

### CI/CD Integration

```yaml
# .github/workflows/performance.yml
name: Performance Regression

on: [pull_request]

jobs:
  regression:
    runs-on: macos-latest # ou runner com GPU
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      
      - name: Run regression tests
        run: |
          cargo bench --features gpu --bench gpu_regression -- --save-baseline pr
      
      - name: Check for regressions
        run: ./scripts/check_performance_regression.sh
```

## ğŸ“ˆ Interpretando Resultados

### Exemplo de Output SaudÃ¡vel

```
regression_minimum_throughput/gradient_1k_states
                        time:   [8.234 ms 8.567 ms 8.912 ms]
                        thrpt:  [114.9K elem/s 119.5K elem/s 124.3K elem/s]
                        
âœ… Throughput: >100K elem/s (acima do mÃ­nimo)
```

### Exemplo de RegressÃ£o

```
regression_minimum_throughput/gradient_1k_states
                        time:   [25.12 ms 26.45 ms 27.89 ms]
                        thrpt:  [36.7K elem/s 38.7K elem/s 40.8K elem/s]
                        change: [+192% +209% +226%] (p = 0.00 < 0.05)
                        
âŒ REGRESSÃƒO: Throughput caiu para 40K elem/s (abaixo de 50K mÃ­nimo)
```

## ğŸ”§ Thresholds Configurados

```rust
// benches/gpu_regression.rs

// Throughput mÃ­nimo: 1024 estados em <20ms
// = 51,200 estados/segundo (baseline conservador)
group.throughput(Throughput::Elements(1024));
group.bench_function("gradient_1k_states", ...);

// LatÃªncia mÃ¡xima: 16 estados em <5ms
// Com config otimizada: <2ms esperado
let config = BatchConfig {
    max_batch_size: 256,
    max_wait_ms: 1,  // Low latency
    channel_size: 64,
};

// Batching advantage: batched vs sequential
// Sequential: N Ã— single_op_time
// Batched: batch_op_time (amortizado)
// Esperado: >5x speedup
```

## ğŸ“Š Benchmarks Detalhados

### 1. Individual Operations

**O que testa**: Overhead mÃ­nimo do sistema
**MÃ©trica**: Tempo para 1 operaÃ§Ã£o
**Threshold**: <5ms

```rust
benchmark_individual_operations
â””â”€â”€ single_gradient: ~2-3ms (M3 Pro)
```

### 2. Batching vs Sequential

**O que testa**: EficiÃªncia do batching
**MÃ©trica**: Speedup (sequential / batched)
**Threshold**: >5x

```rust
benchmark_batching_vs_sequential
â”œâ”€â”€ batched/16:     ~2ms  (16 estados)
â”œâ”€â”€ sequential/16:  ~40ms (16 Ã— 2.5ms)
â””â”€â”€ speedup: 20x âœ…
```

### 3. Minimum Throughput

**O que testa**: Performance absoluta
**MÃ©trica**: Estados/segundo
**Threshold**: >50K/s

```rust
benchmark_minimum_throughput
â””â”€â”€ gradient_1k_states: ~120K/s âœ…
```

### 4. Maximum Latency

**O que testa**: Responsividade
**MÃ©trica**: Tempo de resposta
**Threshold**: <5ms (16 estados)

```rust
benchmark_maximum_latency
â””â”€â”€ latency_16_states: ~1.5ms âœ…
```

### 5. Interpolate Parity

**O que testa**: ConsistÃªncia entre operaÃ§Ãµes
**MÃ©trica**: Ratio (interpolate / gradient)
**Threshold**: 0.8 - 1.2 (Â±20%)

```rust
benchmark_interpolate_parity
â”œâ”€â”€ gradient_256: ~8ms
â”œâ”€â”€ lerp_256:     ~8.5ms (ratio: 1.06 âœ…)
â””â”€â”€ slerp_256:    ~9ms   (ratio: 1.12 âœ…)
```

### 6. Batching Overhead

**O que testa**: Escalabilidade de batch size
**MÃ©trica**: Tempo / num_estados (deve ser constante)
**Threshold**: <10% variaÃ§Ã£o

```rust
benchmark_batching_overhead
â”œâ”€â”€ batch_size=64:   15.6Âµs/estado
â”œâ”€â”€ batch_size=256:  16.2Âµs/estado (+3.8% âœ…)
â”œâ”€â”€ batch_size=1024: 17.1Âµs/estado (+9.6% âœ…)
â””â”€â”€ batch_size=4096: 18.9Âµs/estado (+21% âš ï¸)
```

### 7. Parallel Scalability

**O que testa**: Multi-threading efficiency
**MÃ©trica**: Throughput linear com tasks
**Threshold**: >80% efficiency

```rust
benchmark_parallel_scalability
â”œâ”€â”€ 1 task:  120K/s (baseline)
â”œâ”€â”€ 2 tasks: 216K/s (90% efficiency âœ…)
â”œâ”€â”€ 4 tasks: 408K/s (85% efficiency âœ…)
â””â”€â”€ 8 tasks: 720K/s (75% efficiency âš ï¸)
```

## ğŸ› Troubleshooting

### Benchmark Falhou

```bash
# Verificar se GPU estÃ¡ disponÃ­vel
cargo run --example gpu_batching --features gpu

# Rodar com mais detalhes
cargo bench --features gpu --bench gpu_regression -- --verbose

# Rodar apenas um benchmark especÃ­fico
cargo bench --features gpu --bench gpu_regression -- minimum_throughput
```

### Performance Abaixo do Esperado

1. **Verificar GPU**: Certifique-se que estÃ¡ usando GPU dedicada
2. **Verificar temperatura**: Throttling tÃ©rmico pode reduzir performance
3. **Verificar batch size**: Ajustar `max_batch_size` no config
4. **Verificar concorrÃªncia**: Outros processos usando GPU

### Resultados Inconsistentes

```bash
# Aumentar sample size
cargo bench --features gpu --bench gpu_regression -- --sample-size 100

# Rodar mÃºltiplas vezes
for i in {1..5}; do
    cargo bench --features gpu --bench gpu_regression
done
```

## ğŸ“ Checklist de RegressÃ£o

Antes de merge, verificar:

- [ ] Todos os benchmarks passam
- [ ] Throughput >50K estados/s
- [ ] LatÃªncia <5ms para 16 estados
- [ ] Batching >5x mais rÃ¡pido que sequential
- [ ] InterpolaÃ§Ã£o tem performance similar a gradientes
- [ ] Overhead de batching <10%
- [ ] Escalabilidade paralela >80% atÃ© 4 tasks
- [ ] Script `check_performance_regression.sh` passa

## ğŸ¯ PrÃ³ximos Passos

- [ ] Adicionar testes para NPU quando implementado
- [ ] Comparar com CPU fallback
- [ ] Testes de stress (>10K estados)
- [ ] Memory profiling (leaks, fragmentaÃ§Ã£o)
- [ ] Power consumption benchmarks

## ğŸ“š Ver TambÃ©m

- [GPU_BATCHING.md](GPU_BATCHING.md) - Arquitetura do sistema
- [PERFORMANCE_SUMMARY.md](PERFORMANCE_SUMMARY.md) - OtimizaÃ§Ãµes gerais
- [BENCHMARK_REPORT.md](BENCHMARK_REPORT.md) - Resultados completos

---

**Autor**: SIL-Team  
**VersÃ£o**: 2026.1.0  
**Status**: âœ… Ativo
