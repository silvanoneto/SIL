# ğŸŒ€ SIL-Core

> *"Linguagem intermediÃ¡ria otimizada para processamento de sinais complexos em representaÃ§Ã£o log-polar."*

## O PadrÃ£o SIL

**SIL** = **Signal Intermediate Language** â€” Linguagem intermediÃ¡ria para processamento de sinais complexos

SIL Ã© um design pattern onde:

1. Todo estado Ã© um **vetor de 16 camadas**
2. Cada camada Ã© um **nÃºmero complexo** (Ï, Î¸)
3. O programa Ã© uma **transformaÃ§Ã£o de estados**
4. O ciclo Ã© **fechado** (output â†’ input)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ESTADO SIL (128 bits)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L(0)  L(1)  L(2)  L(3)  L(4)  L(5)  L(6)  L(7)               â”‚
â”‚  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•               â”‚
â”‚  FOT   ACU   OLF   GUS   DER   ELE   PSI   AMB                â”‚
â”‚  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€ PERCEPÃ‡ÃƒO â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ—„â”€â”€â”€ PROCESSO â”€â”€â–º              â”‚
â”‚                                                                 â”‚
â”‚  L(8)  L(9)  L(A)  L(B)  L(C)  L(D)  L(E)  L(F)               â”‚
â”‚  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•  â•â•â•â•               â”‚
â”‚  CIB   GEO   COS   SIN   QUA   SUP   ENT   COL                â”‚
â”‚  â—„â”€â”€â”€ INTERAÃ‡ÃƒO â”€â”€â”€â–ºâ—„â”€â”€ EMERGE â”€â–ºâ—„â”€â”€â”€â”€â”€â”€ META â”€â”€â”€â”€â”€â”€â–º          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Estrutura do Projeto

```
sil-core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ state/           # ByteSil, SilState
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ byte_sil.rs  # Unidade fundamental (Ï, Î¸)
â”‚   â”‚   â””â”€â”€ sil_state.rs # Estado completo (16 camadas)
â”‚   â”‚
â”‚   â”œâ”€â”€ transforms/      # TransformaÃ§Ãµes por fase
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ perception.rs   # L(0-4)
â”‚   â”‚   â”œâ”€â”€ processing.rs   # L(5-7)
â”‚   â”‚   â”œâ”€â”€ interaction.rs  # L(8-A)
â”‚   â”‚   â”œâ”€â”€ emergence.rs    # L(B-C)
â”‚   â”‚   â””â”€â”€ meta.rs         # L(D-F)
â”‚   â”‚
â”‚   â”œâ”€â”€ patterns/        # Design patterns SIL
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ observer.rs     # PadrÃ£o Observer (percepÃ§Ã£o)
â”‚   â”‚   â”œâ”€â”€ strategy.rs     # PadrÃ£o Strategy (processamento)
â”‚   â”‚   â”œâ”€â”€ mediator.rs     # PadrÃ£o Mediator (interaÃ§Ã£o)
â”‚   â”‚   â””â”€â”€ emergent.rs     # PadrÃ£o Emergent (auto-organizaÃ§Ã£o)
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/      # Backends de hardware
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ traits.rs       # Traits comuns
â”‚   â”‚   â”œâ”€â”€ cpu/            # CPU backend (SIMD)
â”‚   â”‚   â”œâ”€â”€ gpu/            # GPU backend (wgpu)
â”‚   â”‚   â””â”€â”€ npu/            # NPU backend (CoreML)
â”‚   â”‚
â”‚   â”œâ”€â”€ vsp/             # Virtual Sil Processor
â”‚   â”‚   â”œâ”€â”€ mod.rs          # VM principal
â”‚   â”‚   â”œâ”€â”€ opcode.rs       # 70+ opcodes
â”‚   â”‚   â”œâ”€â”€ instruction.rs  # Decode + Builder
â”‚   â”‚   â”œâ”€â”€ state.rs        # Registradores, flags
â”‚   â”‚   â”œâ”€â”€ memory.rs       # Segmentos de memÃ³ria
â”‚   â”‚   â”œâ”€â”€ backend.rs      # AbstraÃ§Ã£o CPU/GPU/NPU
â”‚   â”‚   â”œâ”€â”€ bytecode.rs     # Formato .silc
â”‚   â”‚   â””â”€â”€ error.rs        # Tipos de erro
â”‚   â”‚
â”‚   â”œâ”€â”€ cycle/           # Loop fechado
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ loop.rs      # sil_loop principal
â”‚   â”‚
â”‚   â”œâ”€â”€ lib.rs           # Raiz do crate
â”‚   â””â”€â”€ prelude.rs       # Re-exportaÃ§Ãµes convenientes
â”‚
â”œâ”€â”€ Cargo.toml
â””â”€â”€ README.md
```

## InstalaÃ§Ã£o e Requisitos

- Requer Rust `1.92+` e `cargo` instalado
- Suporte cruzado: macOS, Linux e Windows (CPU/Interpreter)
- JIT DynASM: apenas `ARM64` (Apple Silicon/macOS, Linux)

InstalaÃ§Ã£o local (desenvolvimento):

```bash
git clone https://github.com/silvanoneto/
cd sil-core
cargo build
```

## Executar Exemplos

Alguns exemplos Ãºteis disponÃ­veis no diretÃ³rio `examples/`:

```bash
# Interpreter universal (CPU)
cargo run --example vsp_interpreter

# DynASM JIT (ARM64, requer feature)
cargo run --example vsp_dynasm --features dynasm

# Pipeline JSIL (I/O)
cargo run --example jsil_pipeline

# GPU batching (quando habilitar feature gpu)
cargo run --example gpu_batching --features gpu
```

Benchmarks (opcionais):

```bash
# CPU
cargo bench --bench cpu

# GPU (requer --features gpu)
cargo bench --bench gpu --features gpu

# DynASM (ARM64, requer --features dynasm)
cargo bench --bench dynasm_comparison --features dynasm

# Cranelift JIT (requer --features jit)
cargo bench --bench jit_comparison --features jit
```

## Quick Start

```rust
use sil_core::prelude::*;

// Criar estado inicial
let state = SilState::neutral();

// Criar pipeline de transformaÃ§Ãµes
let pipeline = Pipeline::new(vec![
    Box::new(PhaseShift(4)),
    Box::new(MagnitudeScale(2)),
]);

// Executar ciclo SIL
let final_state = sil_loop(state, &pipeline, 100);
```

Build e execuÃ§Ã£o mÃ­nima:

```bash
cargo build
cargo run --example vsp_interpreter
```

## VSP: Virtual Sil Processor

> *"A JVM sÃ³ que realmente aberta."*

**VSP** Ã© a mÃ¡quina virtual que torna a compatibilidade transparente â€” tanto a nÃ­vel de hardware quanto de software.

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VSP (MÃ¡quina Virtual)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Bytecode   â”‚  â”‚   Estado    â”‚  â”‚        MemÃ³ria          â”‚  â”‚
â”‚  â”‚   (.silc)   â”‚  â”‚  (R0-R15)   â”‚  â”‚  Codeâ”‚Stackâ”‚Heapâ”‚I/O    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                â”‚                     â”‚                â”‚
â”‚         â–¼                â–¼                     â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚               Execution Engine (fetch-decode-execute)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â–¼                    â–¼                    â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ CPU Backend â”‚      â”‚ GPU Backend â”‚      â”‚ NPU Backend â”‚      â”‚
â”‚  â”‚  (default)  â”‚      â”‚   (wgpu)    â”‚      â”‚ (Core ML)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ISA (70+ opcodes)

| Categoria | Opcodes | DescriÃ§Ã£o |
|:----------|:--------|:----------|
| Control | `NOP`, `HALT`, `JMP`, `CALL`, `RET` | Fluxo de execuÃ§Ã£o |
| Data | `LOAD`, `STORE`, `MOVE`, `PUSH`, `POP` | ManipulaÃ§Ã£o de dados |
| Arithmetic | `ADD`, `SUB`, `MUL`, `DIV`, `XOR` | OperaÃ§Ãµes em ByteSil |
| Layer | `LGET`, `LSET`, `LXOR`, `LSHIFT` | Acesso Ã s 16 camadas |
| Transform | `PHASE`, `MAG`, `LERP`, `COLLAPSE` | TransformaÃ§Ãµes SIL |
| Compat | `PROMOTE`, `DEMOTE`, `SETMODE` | Modos de compatibilidade |
| System | `SYSCALL`, `IO`, `SYNC` | Interface com sistema |
| Hints | `PREFETCH`, `HINT_GPU`, `HINT_NPU` | OtimizaÃ§Ã£o de backend |

### Modos de Compatibilidade

```
SIL-8   â”€â–º 1 camada   (8 bits)   â”€â–º IoT mÃ­nimo
SIL-16  â”€â–º 2 camadas  (16 bits)  â”€â–º Microcontroladores
SIL-32  â”€â–º 4 camadas  (32 bits)  â”€â–º Embedded
SIL-64  â”€â–º 8 camadas  (64 bits)  â”€â–º Desktop
SIL-128 â”€â–º 16 camadas (128 bits) â”€â–º Full SIL
```

### Execution Engines

VSP oferece **dois backends de execuÃ§Ã£o** com diferentes trade-offs:

#### 1. Native Rust Interpreter (Universal)

**Threaded dispatch** com function pointers e inline optimization:

```rust
use sil_core::vsp::interpreter::VspInterpreter;

let mut interp = VspInterpreter::new();
interp.compile(&program)?;
interp.execute(&mut state)?;
```

âœ… **Vantagens:**

- Funciona em **qualquer arquitetura** (x86-64, ARM64, RISC-V, WASM)
- **257M ops/sec** em Apple Silicon M3 Pro
- Zero dependÃªncias externas
- Hot-swapping de backends (CPU/GPU/NPU)

#### 2. DynASM JIT (ARM64 only)

**Native assembly generation** com zero overhead:

```rust
#[cfg(target_arch = "aarch64")]
use sil_core::vsp::dynasm::VspDynasmJit;

let mut jit = VspDynasmJit::new()?;
jit.compile(&program)?;
jit.execute(&mut state)?;
```

âœ… **Vantagens:**

- **326M ops/sec** em Apple Silicon (27% mais rÃ¡pido)
- Zero overhead de dispatch
- OtimizaÃ§Ãµes especÃ­ficas ARM64

âš ï¸ **LimitaÃ§Ãµes:**

- Apenas ARM64 (macOS/Linux)
- Feature `dynasm` implementada; habilite com `--features dynasm`
- Ganho mÃ¡ximo em programas simples (NOPs, loads); mixed workloads mostram speedup de ~5â€“15Ã—

Build rÃ¡pido (Apple Silicon):

```bash
cargo run --example vsp_dynasm --features dynasm
```

#### Performance Comparison (M3 Pro)

| Engine | Warm Latency/exec | Throughput (10k execs) | Portability |
|:-------|:--:|:--:|:------------|
| **Interpreter** | ~82.5 ns | ~24.5M execs/sec | âœ… x86/ARM/RISC-V/WASM |
| **DynASM JIT** | ~4.2 ns | ~357M execs/sec | âš ï¸ ARM64 only |
| **Speedup** | **~19.6Ã—** | **~14.6Ã—** | - |

**Benchmark methodology:** NOP-heavy program (64 bytes), warm cache, single iteration + loop of 10,000 executions. Speedup varies with instruction mix; pure NOPs favor JIT (less dispatch overhead), while mixed workloads show ~5â€“15Ã— speedup.

#### Choosing an Engine

```rust
// OpÃ§Ã£o 1: Interpreter (recomendado)
let mut engine = VspInterpreter::new();

// OpÃ§Ã£o 2: Auto-select (JIT se disponÃ­vel, senÃ£o interpreter)
#[cfg(all(target_arch = "aarch64", feature = "dynasm"))]
let mut engine = VspDynasmJit::new().unwrap_or_else(|_| {
    VspInterpreter::new()
});

#[cfg(not(all(target_arch = "aarch64", feature = "dynasm")))]
let mut engine = VspInterpreter::new();
```

**RecomendaÃ§Ã£o:**

- **Interpreter DEFAULT**: Oferece portabilidade universal (~24M execs/sec); use para qualquer arquitetura
- **DynASM opcional**: Use apenas no ARM64 se precisar de mÃ¡xima performance (~357M execs/sec, ~15Ã— speedup em NOPs)

### Uso (Legacy API)

```rust
use sil_core::vsp::{Vsp, VspConfig};

// Carregar bytecode
let bytecode = include_bytes!("programa.silc");

// Configurar VM
let config = VspConfig::default()
    .with_memory_size(1024 * 1024)
    .with_mode(SilMode::Sil128);

// Criar e executar
let mut vm = Vsp::new(config);
vm.load(bytecode)?;
let result = vm.run()?;
```

### Bytecode (.silc)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Header (32 bytes)                      â”‚
â”‚  â”œâ”€ Magic: "SILC"                      â”‚
â”‚  â”œâ”€ Version: 1.0                       â”‚
â”‚  â”œâ”€ Mode: SIL-128                      â”‚
â”‚  â””â”€ Segment offsets                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Code Segment                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data Segment                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Symbol Table (opcional)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Debug Info (opcional)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrincÃ­pios SOLID Ã— SIL

| SOLID | PrincÃ­pio SIL | ImplementaÃ§Ã£o |
|:------|:--------------|:--------------|
| **S** | Camadas ortogonais | Uma camada = uma semÃ¢ntica |
| **O** | Estado imutÃ¡vel | Novas transforms sem modificar |
| **L** | TransformaÃ§Ã£o pura | Qualquer impl substitui outra |
| **I** | Traits por fase | Sensor â‰  Processor â‰  Mediator |
| **D** | Estado abstrato | Depende de traits, nÃ£o structs |

## Performance: CPU vs GPU vs NPU

> **Regra:** GPU compensa apenas para **batches â‰¥ 10.000 estados** ou operaÃ§Ãµes muito intensivas.

### Benchmarks (Apple Silicon M3)

#### OperaÃ§Ãµes BÃ¡sicas (CPU)

| OperaÃ§Ã£o | Tempo | Throughput |
|:---------|------:|:-----------|
| `ByteSil::mul` | 586 ps | 1.7B ops/s |
| `ByteSil::xor` | 601 ps | 1.6B ops/s |
| `SilState::tensor` | 21 ns | 47M ops/s |
| `SilState::xor` | 10 ns | 100M ops/s |
| `SilState::collapse` | 1.7 ns | 588M ops/s |

#### Gradientes (CPU)

| OperaÃ§Ã£o | Tempo |
|:---------|------:|
| `Gradient::compute_cpu` (1 estado) | 77 ns |
| `Gradient::compute_cpu` (1000 estados) | 73 Âµs |
| `Gradient::apply_to` (descent step) | 26 ns |
| `gradient_descent` (10 iteraÃ§Ãµes) | 952 ns |
| `gradient_descent` (100 iteraÃ§Ãµes) | 9.5 Âµs |

#### InterpolaÃ§Ã£o (CPU)

| OperaÃ§Ã£o | Tempo |
|:---------|------:|
| `lerp_states` | 12 ns |
| `slerp_states` | 16 ns |
| `bezier_quadratic` | 38 ns |
| `bezier_cubic` | 78 ns |

#### QuantizaÃ§Ã£o: Quantizable vs NPU

| OperaÃ§Ã£o | Quantizable | NPU Tensor | Overhead |
|:---------|------------:|-----------:|---------:|
| `to_int8` / `INT8` | 27 ns | 49 ns | +82% |
| `to_fp16` / `FP16` | 27 ns | 83 ns | +207% |

> **Nota:** O overhead NPU Ã© esperado â€” `NpuTensor` prepara dados para inferÃªncia em ANE/Core ML.

#### Scaling de InterpolaÃ§Ã£o (CPU)

| Steps | Tempo | LatÃªncia/step |
|:------|------:|--------------:|
| 10 | 141 ns | 14.1 ns |
| 50 | 629 ns | 12.6 ns |
| 100 | 1.24 Âµs | 12.4 ns |
| 500 | 6.14 Âµs | 12.3 ns |
| 1000 | 12.2 Âµs | 12.2 ns |

#### InferÃªncia NPU (Core ML / ANE)

| OperaÃ§Ã£o | Tempo |
|:---------|------:|
| `NpuContext::infer` (classifier, 10 classes) | 430 ns |

#### DetecÃ§Ã£o de Processadores

| OperaÃ§Ã£o | Tempo |
|:---------|------:|
| `ProcessorType::available()` | 22 ns |
| `ProcessorType::Cpu::is_available()` | 296 ps |
| `ProcessorType::Gpu::is_available()` | 296 ps |
| `ProcessorType::Npu::is_available()` | 296 ps |

#### Batch Processing (CPU)

| Batch Size | Tempo | LatÃªncia/estado |
|:-----------|------:|----------------:|
| 100 estados (gradient) | 7.32 Âµs | 73.2 ns |

#### GPU Context

| OperaÃ§Ã£o | Tempo |
|:---------|------:|
| `GpuContext::new_sync` | **583 Âµs** |

#### VSP Execution Engines

| Engine | Latency per exec | Peak Throughput | Overhead vs Native Rust |
|:-------|:--:|:--:|:--:|
| **Interpreter (Rust)** | ~82.5 ns | ~24.5M execs/s | ~46x |
| **DynASM JIT (ARM64)** | ~4.2 ns | ~357M execs/s | ~2.3x |
| **Native Rust loop** | ~1.8 ns | ~1.6B ops/s | 1x |

> **Nota:** O overhead VSP Ã© esperado â€” trata-se de uma mÃ¡quina virtual completa com fetch-decode-execute, registradores, memÃ³ria segmentada e abstraÃ§Ã£o de backend. O custo compensa quando:

> - Portabilidade de bytecode Ã© necessÃ¡ria (Interpreter ubÃ­quo; DynASM ARM64-only)
> - Hot-swapping de backends (CPUâ†’GPUâ†’NPU)
> - Debugging avanÃ§ado (DAP/LSP)
> - Compatibilidade entre SIL-8 atÃ© SIL-128
>
> **Overhead reduzido com JIT:** DynASM JIT elimina dispatch indireto, trazendo latÃªncia prÃ³xima ao nativo (4.2 ns vs 1.8 ns em puro loop).

### Regra de DecisÃ£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUANDO USAR.   ?                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Batch Size < 10.000 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º CPU  (overhead GPU > ganho) â”‚
â”‚                                                                 â”‚
â”‚   Batch Size â‰¥ 10.000 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º GPU  (paralelismo compensa) â”‚
â”‚                                                                 â”‚
â”‚   OperaÃ§Ã£o Ãºnica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º CPU  (sempre)               â”‚
â”‚                                                                 â”‚
â”‚   sil_loop (100 ciclos) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º CPU  (1.8 Âµs, muito rÃ¡pido) â”‚
â”‚                                                                 â”‚
â”‚   Treinamento/OtimizaÃ§Ã£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º GPU  (batches grandes)      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API de SeleÃ§Ã£o AutomÃ¡tica

```rust
use sil_core::gpu::{GpuContext, SilGradient};

// CPU: operaÃ§Ãµes individuais
let grad = SilGradient::compute_cpu(&state, 0.01);

// GPU: batches grandes (quando implementado)
// let ctx = GpuContext::new_sync()?;
// let grads = ctx.compute_gradients_batch(&states).await;
```

## Features

```toml
[dependencies]
sil-core = { version = "2026.1", features = ["gpu", "npu"] }
```

| Feature | DescriÃ§Ã£o |
|:--------|:----------|
| `default` | Apenas CPU, sem dependÃªncias extras |
| `gpu` | Habilita wgpu para compute shaders |
| `npu` | Habilita Core ML / ANE para inferÃªncia |
| `simd` | OtimizaÃ§Ãµes SIMD (requer nightly) |
| `python` | Bindings PyO3 para Python |
| `jit` | Habilita JIT/AOT via Cranelift (bin `vsp-aot`) |
| `dynasm` | Habilita JIT nativo ARM64 via DynASM |

Uso com `cargo` (local):

```bash
# GPU
cargo run --example gpu_pipeline_pool --features gpu

# JIT Cranelift (AOT/JIT)
cargo run --bin vsp-aot --features jit

# DynASM ARM64
cargo run --example vsp_dynasm --features dynasm
```

## Roadmap

- [x] ByteSil (unidade fundamental)
- [x] SilState (16 camadas)
- [x] TransformaÃ§Ãµes por fase
- [x] Processadores CPU/GPU/NPU
- [x] VSP (Virtual Sil Processor)
- [x] Assembler (`silasm`: .sil â†’ .silc)
- [x] REPL interativo
- [x] Debugger visual (DAP)
- [x] Distributed sync (entanglement)
- [x] Language Server Protocol (LSP)
- [x] VS Code Extension

## IDE Support

### Language Server Protocol (LSP)

O servidor LSP completo para arquivos `.sil`:

```rust
use sil_core::vsp::lsp::{SilLanguageServer, LspConfig};

let server = SilLanguageServer::new(LspConfig::default());
server.run_stdio();
```

**Funcionalidades:**

- ğŸ¯ **IntelliSense** â€” Auto-complete para opcodes, registradores, diretivas
- ğŸ“– **Hover Info** â€” DocumentaÃ§Ã£o inline de opcodes e registradores
- ğŸ” **Go to Definition** â€” NavegaÃ§Ã£o para labels
- ğŸ“‹ **Document Symbols** â€” Outline de cÃ³digo
- âš ï¸ **Diagnostics** â€” Erros e warnings em tempo real
- ğŸ¨ **Semantic Tokens** â€” Syntax highlighting avanÃ§ado
- âœ¨ **Formatting** â€” FormataÃ§Ã£o automÃ¡tica de cÃ³digo

### VS Code Extension

ExtensÃ£o completa em `sil-vscode/`:

```bash
cd sil-vscode
npm install
npm run compile
# F5 para Extension Development Host
```

**Inclui:**

- ğŸŒˆ Syntax Highlighting (TextMate grammar)
- ğŸ“ Snippets para templates comuns
- ğŸ› Debug Adapter Protocol (DAP)
- âš¡ Comandos: Assemble, Run, Debug, REPL
- âš™ï¸ ConfiguraÃ§Ãµes: mode, format, diagnostics

## LicenÃ§a

AGPL-3.0
