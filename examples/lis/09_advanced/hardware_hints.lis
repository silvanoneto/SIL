// LIS Example: Hardware Hints
// Demonstra: @cpu, @gpu, @npu, @simd, @photonic
// Documentação: Seção 3.3

// =========================================
// Conceito de Hardware Hints
// =========================================
// LIS é "hardware-aware" - permite indicar onde
// o código deve ser executado para otimização.
//
// Hardware hints são anotações que direcionam
// a execução para hardware específico:
// - @cpu    : CPU tradicional
// - @gpu    : GPU (Graphics Processing Unit)
// - @npu    : NPU (Neural Processing Unit)
// - @simd   : Operações SIMD
// - @photonic: Computação fotônica
//
// NOTA: Hardware hints vêm APÓS o tipo de retorno:
// fn nome() -> Tipo @hint { ... }

// =========================================
// @cpu - Execução em CPU
// =========================================

fn cpu_computation(a: Int, b: Int) -> Int @cpu {
    // Esta função será executada na CPU
    return a + b;
}

fn cpu_heavy_loop(n: Int) -> Int @cpu {
    let sum = 0;
    let i = 0;
    loop {
        if i >= n {
            break;
        }
        let sum = sum + i;
        let i = i + 1;
    }
    return sum;
}

// =========================================
// @gpu - Execução em GPU
// =========================================

fn gpu_matrix_op(input: State, weights: State) -> State @gpu {
    // Operações paralelas em GPU
    // Ideal para operações matriciais
    return state_tensor(input, weights);
}

fn gpu_parallel_transform(s: State) -> State @gpu {
    // Transformações paralelas em todas as camadas
    return transform_magnitude_scale(s, 2);
}

// =========================================
// @npu - Neural Processing Unit
// =========================================

fn npu_inference(input: State, model_weights: State) -> State @npu {
    // Inferência em NPU otimizada para ML
    let weighted = state_tensor(input, model_weights);
    return relu_state(weighted);
}

fn npu_forward_pass(x: State, w1: State, w2: State) -> State @npu {
    // Forward pass de rede neural em NPU
    let h1 = state_tensor(x, w1);
    let h1 = relu_state(h1);
    let output = state_tensor(h1, w2);
    return output;
}

// =========================================
// @simd - Operações SIMD
// =========================================

fn simd_vector_add(a: State, b: State) -> State @simd {
    // Soma vetorizada usando instruções SIMD
    return state_xor(a, b);
}

fn simd_batch_normalize(s: State) -> State @simd {
    // Normalização usando operações vetorizadas
    return state_normalize(s);
}

// =========================================
// @photonic - Computação Fotônica
// =========================================

fn photonic_interference(a: State, b: State) -> State @photonic {
    // Simulação de interferência fotônica
    // Operações em números complexos são naturais para fotônica
    return state_xor(a, b);
}

fn photonic_transform(s: State) -> State @photonic {
    // Transformação de fase (natural em fotônica)
    return transform_phase_shift(s, 2);
}

// =========================================
// Combinação de Hardware
// =========================================

fn cpu_preprocess(s: State) -> State @cpu {
    return state_normalize(s);
}

fn gpu_compute(s: State) -> State @gpu {
    let s = transform_magnitude_scale(s, 2);
    let s = transform_phase_shift(s, 4);
    return s;
}

fn npu_infer(s: State) -> State @npu {
    return relu_state(s);
}

fn hybrid_pipeline(input: State) -> State {
    // Pipeline que usa diferentes aceleradores

    // Pré-processamento em CPU
    let preprocessed = cpu_preprocess(input);

    // Computação pesada em GPU
    let computed = gpu_compute(preprocessed);

    // Inferência em NPU
    let output = npu_infer(computed);

    return output;
}

// =========================================
// Funções sem Hint (Default)
// =========================================

// Sem anotação, o runtime decide o hardware
fn auto_scheduled(s: State) -> State {
    return state_normalize(s);
}

fn main() {
    print_string("=== Hardware Hints Demo ===");

    // =========================================
    // CPU Operations
    // =========================================
    print_string("--- CPU Operations ---");

    let cpu_result = cpu_computation(10, 20);
    print_string("CPU add result:");
    print_int(cpu_result);

    let cpu_sum = cpu_heavy_loop(100);
    print_string("CPU loop sum 0..99:");
    print_int(cpu_sum);

    // =========================================
    // GPU Operations
    // =========================================
    print_string("--- GPU Operations ---");

    let input = state_neutral();
    let weights = state_neutral();

    let gpu_result = gpu_matrix_op(input, weights);
    print_string("GPU matrix op complete");

    // =========================================
    // NPU Operations
    // =========================================
    print_string("--- NPU Operations ---");

    let x = state_neutral();
    let w = state_neutral();

    let npu_result = npu_inference(x, w);
    print_string("NPU inference complete");

    // =========================================
    // SIMD Operations
    // =========================================
    print_string("--- SIMD Operations ---");

    let a = state_neutral();
    let b = state_neutral();

    let simd_result = simd_vector_add(a, b);
    print_string("SIMD vector add complete");

    // =========================================
    // Photonic Operations
    // =========================================
    print_string("--- Photonic Operations ---");

    let phot_result = photonic_transform(state_neutral());
    print_string("Photonic transform complete");

    // =========================================
    // Hybrid Pipeline
    // =========================================
    print_string("--- Hybrid Pipeline ---");

    let pipeline_input = state_neutral();
    let pipeline_output = hybrid_pipeline(pipeline_input);
    print_string("Hybrid pipeline complete");

    print_string("=== Hardware Hints Demo Complete ===");
}
