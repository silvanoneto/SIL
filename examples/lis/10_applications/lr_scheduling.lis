// LIS Example: Learning Rate Scheduling
// Demonstra: Cosine annealing, linear warmup e outros schedulers
// Documentação: Seção 12.8

// =========================================
// Constant Learning Rate
// =========================================

fn lr_constant(initial: Float, step: Int) -> Float {
    return initial;
}

// =========================================
// Step Decay
// =========================================

fn lr_step_decay(initial: Float, step: Int, decay_steps: Int, decay_rate: Float) -> Float {
    let num_decays = step / decay_steps;
    let factor = 1.0;
    let i = 0;

    loop {
        if i >= num_decays {
            break;
        }
        let factor = factor * decay_rate;
        let i = i + 1;
    }

    return initial * factor;
}

// =========================================
// Exponential Decay
// =========================================

fn lr_exponential_decay(initial: Float, step: Int, decay_rate: Float) -> Float {
    let factor = 1.0;
    let i = 0;

    loop {
        if i >= step {
            break;
        }
        let factor = factor * decay_rate;
        let i = i + 1;
    }

    return initial * factor;
}

// =========================================
// Linear Warmup
// =========================================

fn lr_linear_warmup(target_lr: Float, step: Int, warmup_steps_p: Int) -> Float {
    if step >= warmup_steps_p {
        return target_lr;
    }
    return target_lr * step * 1.0 / warmup_steps_p * 1.0;
}

// =========================================
// Cosine Annealing
// =========================================

fn lr_cosine_annealing(initial: Float, step: Int, total: Int, min_val: Float) -> Float {
    let progress = step * 1.0 / total * 1.0;
    let cos_val = cos(pi() * progress);
    return min_val + 0.5 * (initial - min_val) * (1.0 + cos_val);
}

// =========================================
// Warmup + Cosine Annealing
// =========================================

fn lr_warmup_cosine(initial: Float, step: Int, warmup: Int, total: Int, min_val: Float) -> Float {
    if step < warmup {
        return initial * step * 1.0 / warmup * 1.0;
    }

    let cosine_steps = total - warmup;
    let cosine_step = step - warmup;
    let progress = cosine_step * 1.0 / cosine_steps * 1.0;
    let cos_val = cos(pi() * progress);
    return min_val + 0.5 * (initial - min_val) * (1.0 + cos_val);
}

// =========================================
// One Cycle Policy
// =========================================

fn lr_one_cycle(max_lr: Float, step: Int, total: Int) -> Float {
    let half = total / 2;

    if step < half {
        let progress = step * 1.0 / half * 1.0;
        return max_lr * progress;
    } else {
        let progress = (step - half) * 1.0 / half * 1.0;
        return max_lr * (1.0 - progress);
    }
}

fn main() {
    print_string("=== Learning Rate Scheduling ===");

    let initial_lr = 0.1;
    let min_lr = 0.001;
    let total_steps = 100;
    let warmup_steps = 10;

    // =========================================
    // Constant Learning Rate
    // =========================================
    print_string("--- Constant LR ---");
    print_string("Constant LR at any step:");
    print_float(lr_constant(initial_lr, 50));

    // =========================================
    // Step Decay
    // =========================================
    print_string("--- Step Decay ---");
    print_string("Step 0:");
    print_float(lr_step_decay(initial_lr, 0, 10, 0.5));
    print_string("Step 10:");
    print_float(lr_step_decay(initial_lr, 10, 10, 0.5));
    print_string("Step 20:");
    print_float(lr_step_decay(initial_lr, 20, 10, 0.5));

    // =========================================
    // Linear Warmup
    // =========================================
    print_string("--- Linear Warmup ---");
    print_string("Step 0:");
    print_float(lr_linear_warmup(initial_lr, 0, warmup_steps));
    print_string("Step 5:");
    print_float(lr_linear_warmup(initial_lr, 5, warmup_steps));
    print_string("Step 10:");
    print_float(lr_linear_warmup(initial_lr, 10, warmup_steps));

    // =========================================
    // Cosine Annealing
    // =========================================
    print_string("--- Cosine Annealing ---");
    print_string("Step 0:");
    print_float(lr_cosine_annealing(initial_lr, 0, total_steps, min_lr));
    print_string("Step 50:");
    print_float(lr_cosine_annealing(initial_lr, 50, total_steps, min_lr));
    print_string("Step 100:");
    print_float(lr_cosine_annealing(initial_lr, 100, total_steps, min_lr));

    // =========================================
    // One Cycle Policy
    // =========================================
    print_string("--- One Cycle Policy ---");
    print_string("Step 0:");
    print_float(lr_one_cycle(initial_lr, 0, 100));
    print_string("Step 50 (peak):");
    print_float(lr_one_cycle(initial_lr, 50, 100));
    print_string("Step 100:");
    print_float(lr_one_cycle(initial_lr, 100, 100));

    print_string("=== LR Scheduling Demo Complete ===");
}
